{
  "hash": "2f3a722672015d61727169fd5b2d87e9",
  "result": {
    "markdown": "---\ntitle: \"Lab 4: Probability distributions (solutions)\"\nauthor: \\copyright 2005 Ben Bolker, modified at some places by Alejandro Morales & Bob Douma 2019\ndate: \"October 11, 2019\"\ncache: true\nparams:\n  solution: true\n---\n---\ntitle: \"Lab 4: Probability distributions\"\nauthor: \\copyright 2005 Ben Bolker, modified at some places by Alejandro Morales & Bob Douma 2019\ndate: \"October 11, 2019\"\ncache: true\nparams:\n  solution: false\n# output:\n#   bookdown::pdf_book:\n#      includes:\n#         in_header: 'preamble1.tex'\n#   word_document: default\n#   html_document:\n#     fig_caption: yes\n#     fig_height: 4.5\n#     fig_width: 5\n#     number_sections: yes\n# geometry: margin=3cm\n# fontsize: 11pt\n---\n\n::: {.cell hash='solution_cache/html/setup_c7ba8a92e41da7091a98a9d782fe9edf'}\n\n:::\n\n# Learning goals\nThis lab has two goals. First, helps you practicing with probability distributions on different types of data (section 2). Second, to make you familiar with the technicalities of stochastic distributions in `R`. In particular, how to generate values from probability distributions and how to make your own probability distribution  (section 3-7).  Under time constraints, make sure that you make at least the exercises in section 2, 3 and 4.\n\n\n# Choosing probability distributions\nIn this exercise we revisit exercise 2.1 of lab 3. In that exercise we had six different datasets each describing a biological phenomenon. The first step to model your data is to choose a deterministic function that describes the mean effect of the predictor variable (x) on the response variable (y). The second step involves the choice of the stochastic distribution which describes how the data varies around the mean.\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-1_631e52b3aaeb24febb91dbf9fa95c3c8'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">Reload the six datasets and choose for each dataset one or two candidate probability distributions.\n  _hint_: ask yourself a number of questions: Do I have counts (integer) or continuous (real) values? Do I have positive values only or also negative values?\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-2_399e37375bf0f4a28915f9505abe1c4f'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">1. Dataset 1\ny represents real numbers and both positive and negative numbers occur. This implies that we should choose a continuous probability distribution. In addition, the numbers seems unbound. Within the family of continuous probability distributions, the normal seems a good candidate distribution because this one runs from -$\\inf$ to +$\\inf$. In contrast the Gamma and the Lognormal only can take positive numbers, so these distributions cannot handle the negative numbers. In addition, the beta distribution is not a good candidate because it runs from 0-1.\n\n2. dataset 2\ny represents real numbers and only positive numbers occur. The data represents a functional response (intake rate of the predator), and it is likely that you can only measure positive numbers (number of prey items per unit of time).  This implies that we should choose a continuous probability distribution. Within the family of continuous probability distributions, the Gamma and the Lognormal could be taken as candidate distributions because they can only take positive numbers (beware that the Gamma cannot take 0). However, you could try to use a normal as well.\n\n3. Dataset 3\ny seems represents counts (this is the cone dataset that is introduced in ch. 6.). Given that it contains counts we can pick a distribution from the family of discrete distributions. The Poisson and the Negative Binomial could be good candidates to describe this type of data.\n\n4. Dataset 4\n      y represents population size over time. From looking at the data, they seems to represent counts. Given that it contains counts we can pick a distribution from the family of discrete distributions. The Poisson and the Negative Binomial could be good candidates to describe this type of data.\n\n5. Dataset 5\nNo information is given on y. The data clearly seems to represent counts. Thus the same reasoning applies here as to the two previous datasets.\n\n6. Dataset 6\nThe data (y) represents species occurences (presence/absence). The binomial model would be a good model to predict the probability of presence.\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\n\n# Random distributions in `R`\n`R` knows about lots of probability distributions.  For each, it\ncan generate random numbers drawn from the distribution (\"random numbers\"); compute the cumulative distribution function and the probability distribution function; and compute the quantile function, which gives the\n$x$ value such that $\\int_0^x P(x) \\, dx$ (area under the curve from 0 to $x$) is a specified value, such as 0.95 (think about \"tail areas\" from standard statistics).\n\n\nLet's take the binomial distribution (yet again) as an example.\n\n- `rbinom(n,size,prob)` gives `n` random draws from the binomial\ndistribution with parameters `size` (total number of draws) and\n`p` (probability of success on each draw).\nYou can give different parameters for each draw.\nFor example:\n  ::: {.cell hash='solution_cache/html/unnamed-chunk-3_9023f2b6419a663b8ab8583e40f8b42c'}\n  \n  ```{.r .cell-code}\n  rbinom(10,size=8,prob=0.5)\n  rbinom(3,size=8,prob=c(0.2,0.4,0.6))\n  ```\n  :::\nFigure 1 shows the result of drawing 200 values from a binomial distribution with $N=12$ and $p=0.5$ and\nplotting the results as a `factor` (with 5000 draws we don't have to worry about any of the 13 possible outcomes getting missed and excluded from the plot):\n  ::: {.cell hash='solution_cache/html/unnamed-chunk-4_43935767825b67877fafc7beff0eb6f3'}\n  \n  ```{.r .cell-code}\n  set.seed(1)\n  plot(factor(rbinom(5000,size=12,prob=0.5)), xlab=\"# of successes\",\n       ylab=\"# of trials out of 200\")\n  ```\n  :::\n\n- `dbinom(x,size,prob)` gives the value of the probability of getting excactly $x$ successes based on the probability distribution. For a continous distribution, the analogous function would compute the probability density function (pdf). Since the binomial is discrete, `x` has to be an integer, and the pdf is just the probability of getting that many successes; if you try `dbinom` with a non-integer `x`, you'll get zero and a warning.\n\n- `pbinom(q,size,prob)` gives the value of the cumulative distribution function (cdf) at `q` (e.g. `pbinom(7,size=10,prob=0.4)`);\n\n- `qbinom(p,size,prob)` gives the quantile function $x=q(p)$, where `p` is a number between 0 and 1 (an area under the pdf, or value of the cdf) and $x$ is the value such that  $P(X \\le x)=p$. The *quantile function* $Q$ is the inverse of the cumulative distribution function $C$: if $Q(p)=q$ then $C(q)=p$.\nExample: `qbinom(0.95,size=10,prob=0.4)`.\n\n\nThese four functions exist for each of the distributions `R` has built in: e.g. for the normal distribution they're `rnorm()`, `pnorm()`, `dnorm()`, `qnorm()`. Each distribution has its own set of parameters (so e.g. `pnorm()` is `pnorm(x,mean=0,sd=1)`). See Figure 2 for a graphical illustration of the four functions.To see which distributions are available in the `base` package; check `?distributions`.\n\n\n\n::: {.cell fig='true' hash='solution_cache/html/unnamed-chunk-5_6dece3cbd1b9d0f23900cb85680399e8'}\n::: {.cell-output-display}\n![Results of `rbinom`](solution_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n::: {.cell hash='solution_cache/html/unnamed-chunk-6_8426cfa4f9d3fd8f06703ced783909f3'}\n::: {.cell-output-display}\n![`R` functions for the Normal distribution, showing probability density function (`dnorm`), and cumulative distribution function (`pnorm`). Random samples are drawn  proportionally to the probability density function with `rnorm` and quantiles are calculated with by inverting the cumulative distribution function with `qnorm`.](solution_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell hash='solution_cache/html/unnamed-chunk-7_df6fca38801b8e6df25a411ccdfcc616'}\n\n:::\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-8_e7287b6977a5e83341d78cc49bd5e358'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">For the binomial distribution with 10 trials and a success probability\nof 0.2:\n\n1. Pick 8 random values and sort them into increasing order\n(if you `set.seed(1001)` beforehand, you should get $X=0$\n(twice), $X=2$ (4 times), and $X=4$ and $X=5$ (once each)).\n\n2. Calculate the probabilities of getting 3, 4, or 5\nsuccesses first by hand (See Ch.4) and check it with the computer. Answer:\n\n3. Calculate the probability of getting 5 or more\nsuccesses.\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-9_c9ca9ae86b2ac154efb4292b17724e72'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">\n\n1.\n\n`set.seed(1001)`\n`rbinom(8,prob=0.2,size=10)`\n\n2.\n\n`dbinom(3:5,size=10,prob=0.2)`\n\n3.\n\n`pbinom(4,size=10,prob=0.2,lower.tail=FALSE)`\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\nYou can use the `R` functions to test your understanding of\na distribution and make sure that random draws match up\nwith the theoretical distributions as they should.\nThis procedure is particularly valuable when you're developing new\nprobability distributions by combining simpler ones,\ne.g. by zero-inflating or compounding distributions.\n\nThe results of a large number of random draws should have\nthe correct moments (mean and variance), and a histogram\nof those random draws (with `freq=FALSE` or `prob=TRUE`)\nshould match up with the theoretical distribution.\nFor example, draws from a binomial distribution with\n$p=0.2$ and $N=20$ should have a mean of approximately $Np=4$\nand a variance of $Np(1-p)=3.2$:\n::: {.cell hash='solution_cache/html/unnamed-chunk-10_57f1c802cacf79df1f484f68d52ddf01'}\n\n```{.r .cell-code}\nset.seed(1001)\nN=20; p=0.2\nx = rbinom(10000,prob=p,size=N)\nc(mean(x),var(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.001200 3.144913\n```\n:::\n:::\n\nThe mean is very close, the variance\nis a little bit farther off.\nJust for the heck of it, we can use the\n`replicate()` function to re-do this\ncommand many times and see how close we get:\n::: {.cell hash='solution_cache/html/unnamed-chunk-11_8ad043c0d6de09ccc8167029dc5a8da9'}\n\n```{.r .cell-code}\nvar_dist = replicate(1000,var(rbinom(10000,prob=p,size=N)))\n```\n:::\n(this may take a little while; if it takes too long,\nlower the number of replicates to 100).\n\nLooking at the summary statistics and\nat the 2.5% and 97.5% quantiles of the\ndistribution of variances:\n::: {.cell hash='solution_cache/html/unnamed-chunk-12_c00d98dfda0546a3ba8742464ddb924c'}\n\n```{.r .cell-code}\nsummary(var_dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.052   3.169   3.199   3.199   3.229   3.340 \n```\n:::\n\n```{.r .cell-code}\nquantile(var_dist,c(0.025,0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    2.5%    97.5% \n3.114357 3.285333 \n```\n:::\n:::\n(Try a histogram too.)\nEven though there's some variation (of\nthe variance) around the theoretical value,\nwe seem to be doing the right thing since\nthe 95% confidence limits include the theoretical\nvalue.\n(Lab 5 will go into more detail on running\nsimulations to check the expected variation\nof different measurement as a function\nof parameters and sample size.)\n\n::: {.cell fig='true' hash='solution_cache/html/unnamed-chunk-13_7d27a5502c42442ddbf777f4a7cd8189'}\n::: {.cell-output-display}\n![Checking random draws from a binomial distribution against theoretical values.](solution_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\nFinally, Figure 3 shows the entire simulated frequency distribution along with the theoretical values.\nThe steps in `R` are:\n\n**1.** pick 10,000 random deviates:\n::: {.cell hash='solution_cache/html/unnamed-chunk-14_18d41d305d71ac94ec68db7bb0a27fd5'}\n\n```{.r .cell-code}\nx = rbinom(10000,prob=p,size=N)\n```\n:::\n\n**2.** Tabulate the values, and divide\nby the number of samples to get\na probability distribution:\n::: {.cell hash='solution_cache/html/unnamed-chunk-15_4d686be27283fbbbe72c109aa3694c1a'}\n\n```{.r .cell-code}\ntx = table(factor(x,levels=0:12))/10000\n```\n:::\n(The `levels`\ncommand is necessary in this case\nbecause the probability of\n$x=12$ with $p=0.2$ and $N=12$\nis actually so low ($\\approx 4\\times 10^{-9}$)\nthat it's very unlikely that\na sample of 10,000 won't include any\nsamples with 12 successes.)\n\n**3.** Draw a barplot of the values, extending\nthe $y$-limits a bit to make room for\nthe theoretical values and saving the\n$x$ locations at which the bars are drawn:\n\n::: {.cell hash='solution_cache/html/unnamed-chunk-16_bdedc9a55b10eae176aab65f5445134e'}\n\n```{.r .cell-code}\nb1 = barplot(tx,ylim=c(0,0.23),ylab=\"Probability\")\n```\n:::\n\n**4.** Add the theoretical values, plotting them\nat the same $x$-locations as the centers\nof the bars:\n::: {.cell hash='solution_cache/html/unnamed-chunk-17_bee8f7e7d1a62df75c14686ccb911802'}\n\n```{.r .cell-code}\npoints(b1,dbinom(0:12,prob=p,size=N),pch=16)\n```\n:::\n(`barplot()` doesn't put the bars\nat $x$ locations corresponding to their\nnumerical values, so you have to save\nthose values as `b1` and re-use\nthem to make sure the theoretical\nvalues end up in the right place.)\n\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-18_cc80e742577f212666ec41de1d978ff6'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">Pick 10,000 negative binomial\ndeviates with $\\mu=2$, $k=0.5$\n(using `rnbinom()`). In `rbnbinom()` $\\mu$ = `mu` and $k$ = `size`.\nPick one of the ways above to draw\nthe distribution.\nCheck that the mean and variance\nagree reasonably well with the theoretical values.\nAdd points representing\nthe theoretical distribution to the plot.\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-19_6930be820eb093045fb03b84a55ef4a7'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">\n`mu = 2`\n\n`k = 0.5`\n\n`x = rnbinom(10000, mu = mu, size = k)`\n\n`tx = table(factor(x, levels = 0:max(x)))/10000`\n\n`b1 = barplot(tx, ylab = \"Probability\")`\n\n`points(b1, dnbinom(0:max(x), mu = mu, size = k), pch = 1)`\n\n`mean(x)`\n\n`var(x)`\n\n`mu`\n\n`mu * (1 + mu/k)`\n\nThe alternative parameterisation:\n\n`p = 1/(1 + mu/k)`\n\n`n = k`\n\n`b1 = barplot(tx, ylab = \"Probability\")`\n\n`points(b1, dnbinom(0:max(x), mu = mu, size = k), pch = 1)`\n\n`points(b1, dnbinom(0:max(x), prob = p, size = k), pch = 2)`\n\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\n\nDoing the equivalent plot for continuous distributions is actually somewhat easier, since you don't have\nto deal with the complications of a discrete distribution: just use `hist(...,prob=TRUE)` to show the\nsampled distribution (possibly with `ylim` adjusted for the maximum of the theoretical density distribution) and `ddist(x,[parameters])` to add the theoretical curve (e.g.: `curve(dgamma(x,shape=2,scale=1),add=TRUE)`).\n\n# Averaging distributions\n\nSuppose we have a (tiny) data set; we can organize it in two different ways, in standard long format or in tabular form:\n::: {.cell hash='solution_cache/html/unnamed-chunk-20_c62189943e3fcb2f948cf1b19073b39d'}\n\n```{.r .cell-code}\ndat = c(5,6,5,7,5,8); dat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5 6 5 7 5 8\n```\n:::\n\n```{.r .cell-code}\ntabdat=table(dat); tabdat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndat\n5 6 7 8 \n3 1 1 1 \n```\n:::\n:::\nTo get the (sample) probability distribution of the data,\njust scale by the total sample size:\n::: {.cell hash='solution_cache/html/unnamed-chunk-21_70287341e6b8c7372c7c561043e3a4b6'}\n\n```{.r .cell-code}\nprob=tabdat/length(dat); prob\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndat\n        5         6         7         8 \n0.5000000 0.1666667 0.1666667 0.1666667 \n```\n:::\n:::\n(dividing by `sum(tabdat)` would\nbe equivalent).\n\nIn the long format, we can take the mean with `mean(dat)` or, replicating the formula $\\sum x_i/N$\nexactly, `sum(dat)/length(dat)`.\n\nIn the tabular format, we can calculate the mean with the formula $\\sum P(x) x$,\nwhich in `R` would be `sum(prob*5:8)` or more generally\n::: {.cell hash='solution_cache/html/unnamed-chunk-22_89a8cac836242de73c08ec25a68eddce'}\n\n```{.r .cell-code}\nvals = as.numeric(names(prob))\nsum(prob*vals)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6\n```\n:::\n:::\n\n`names` extracts the names of the vector and `as.numeric` transform characters to numbers.\nYou could also get the values by `as.numeric(levels(prob))`, or by `sort(unique(dat))`.\n\nHowever, `mean(prob)` or `mean(tabdat)` is just plain wrong (at least, I can't think of a situation where\nyou would want to calculate this value).\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-23_79cda76053b2af355a5b79bdcb6715d6'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">Figure out what you do if you calculate `mean(tabdat)`\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-24_8ea78eba396348ae35a0d6dd926dde00'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">\n`dat = c(5,6,5,7,5,8)`;\n\n`dat`\n\n`tabdat=table(dat)`\n\n`tabdat`\n\n`mean(tabdat)`\n\nIt is the mean of the frequencies, and so this is not what you want to know.\n\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\nGoing back the other way, from a table to raw values, we can use\nthe `rep()` function to repeat values an appropriate number of times.\nIn its simplest form, `rep(x,n)` just creates\na vector repeats `x` (which\nmay be either a single value or a vector) `n` times, but\n**if n is a vector as well** then each element of `x`\nis repeated the corresponding number of times: for example,\n::: {.cell hash='solution_cache/html/unnamed-chunk-25_a448b5eb4575a70183a033671268769f'}\n\n```{.r .cell-code}\nrep(c(1,2,3),c(2,1,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 1 2 3 3 3 3 3\n```\n:::\n:::\ngives two copies of 1, one copy of 2, and five copies of 3.\n\nTherefore,\n::: {.cell hash='solution_cache/html/unnamed-chunk-26_9334abc86d2cb39f51ccd6b3599b4530'}\n\n```{.r .cell-code}\nrep(vals,tabdat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5 5 5 6 7 8\n```\n:::\n:::\nwill recover our original data (although not in the original\norder) by repeating each element of `vals`\nthe correct number of times.\n\n## Jensen's inequality\n\nJensen's inequality states the following: Suppose\nyou have a number of values, $x$, with a mean $\\bar{x}$, and a non-linear\nfunction $f(x)$. Then the mean of $f(x)$ is not equal to $f(\\bar{x})$.\n\nJensen's inequality can be important in a number of cases. The first one is mentioned in Ch. 4 (page 104) how variability can change the mean behaviour of a system (damselfish). Another example where Jensen's inequality kicks in is when transforming your data. Data-transformations are commonly applied to get normally distributed errors.\n\nIn statistical models, you often estimate the mean effect of a given treatment.\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-27_3ae979417cc2df357d1e2b751abc1c73'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">Find out what the effect of Jensen's inequality is on a series of log-tranformed datapoints with respect to the estimated mean.\n\nUse the following pseudo-code:\n1. Generate 10 random deviates from a uniform distribution (choose the range of 0 to 10).\n2. Calculate the mean of those 10 deviates.\n3. Plot the function $\\log(x)$ with curve on the range from 0-10, and plot your numbers onto it\n4. Calculate the mean of the log-transformed values and transform this mean back the normal scale, and compare to the mean calculated at 1.\n5. Plot the means with `abline(h=...)` if you want to draw a horizontal line or `abline(v=...)` to draw a vertical line.\n6.Explain differences between the two means.\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-28_1e96f6d3432a67d0a148d796f274bdbd'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">\n1. `rf = runif(10,min=0,max=10)`\n2. `mean(rf)`\n3. `plot(log(rf)~ rf)`\n    `curve(log(x),add=T)`\n4. `exp(mean(log(rf)))` versus `mean(rf)`\n\n5. `segments(x0=0,y0=log(mean(rf)),x1=mean(rf),\n             y1=log(mean(rf)),lty=1)`\n  `segments(x0=mean(rf),y0=0,x1=mean(rf),\n            y1=log(mean(rf)),lty=1)`\n`segments(x0=0,y0=mean(log(rf)),x1=exp(mean(log(rf))),\n          y1=mean(log(rf)),lty=2)`\n\nA dotted line for the mean of the log transformed values\n\n`segments(x0=exp(mean(log(rf))),y0=mean(log(rf)),\n          x1=exp(mean(log(rf))),\n          y1=min(log(rf)),lty=2)`\n\nBy doing a log transformation first, the higher values are \"compressed\" and weigh less into the mean.\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\n\nThis exercise shows that it is usually a good idea to leave variables untransformed when estimating the properties from this data.\n\n\n# The method of moments: reparameterizing distributions\n\nIn the chapter, I showed how to use the *method of moments*\nto estimate the parameters of a distribution by setting the\nsample mean and variance ($\\bar x$, $s^2$) equal to the theoretical\nmean and variance of a distribution and solving for the parameters.\nFor the negative binomial, in particular, I found $\\mu=\\bar x$\nand $k=(\\bar x)/(s^2/\\bar x -1)$.\n\nYou can also define your own functions that use\nyour own parameterizations: call them `my_function`\nrather than just replacing the standard `R` functions\n(which will lead to insanity in the long run).\n\nFor example, defining\n::: {.cell hash='solution_cache/html/unnamed-chunk-29_a1f201e70f7910213d67d783be5f26bc'}\n\n```{.r .cell-code}\nmy_dnbinom = function(x,mean,var,...) {\n  mu = mean\n  k = mean/(var/mean-1)\n  dnbinom(x,mu=mu,size=k,...)\n}\n\nmy_rnbinom = function(n,mean,var,...) {\n  mu = mean\n  k = mean/(var/mean-1)\n  rnbinom(n,mu=mu,size=k,...)\n}\n```\n:::\n(the `...` in the function takes any other arguments\nyou give to `my_dnbinom` and just passes them through,\nunchanged, to `dnbinom`).\n\nDefining your own functions can be handy if you need\nto work on a regular basis with a distribution that\nuses a different parameterization than the one built\ninto the standard `R` function.\n\nYou can use the kinds of histograms shown above to test your\nresults (remembering that the method of moments estimates\nmay be slightly biased especially for small samples --- but\nthey shouldn't cause errors as large as those caused by\ntypical algebra mistakes).\n\n::: {.cell hash='solution_cache/html/unnamed-chunk-30_ad8dddb2c69315b64b94ffe81078af10'}\n\n```{.r .cell-code}\nx = my_rnbinom(100000,mean=1,var=4)\nmean(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.99864\n```\n:::\n\n```{.r .cell-code}\nvar(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.996378\n```\n:::\n:::\n\n::: {.cell hash='solution_cache/html/unnamed-chunk-31_4719b877d69af1b4f1ab9c44f3886b7a'}\n\n```{.r .cell-code}\ntx = table(factor(x,levels=0:max(x)))/100000\nb1 = barplot(tx,ylab=\"Probability\")\npoints(b1,my_dnbinom(0:max(x),mean=1,var=4),pch=16)\nabline(v=1)\n```\n\n::: {.cell-output-display}\n![](solution_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-32_95ce9d9c23ded30b610b1e59172fb91a'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">Morris (1997) gives a definition of the beta function that\nis different from the standard statistical parameterization.\nThe standard parameterization is\n$$\n\\mbox{Beta}(x|a,b) = \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} x^{a-1}(1-x)^{b-1}\n$$\nwhereas Morris uses\n$$\n\\mbox{Beta}(x|P,\\theta) = \\frac{\\Gamma(\\theta)}{\\Gamma(\\theta P)\\Gamma(\\theta (1-P))} x^{\\theta P-1} (1-x)^{\\theta(1-P)-1}.\n$$\n\n  1. Find expressions for $P$ and $\\theta$ in terms of $a$ and $b$\nand vice versa (use pen and paper).\n  2. Explain why you might prefer Morris's parameterization.\n  3. Define a new set of functions that generate random numbers from the beta distribution (`my_rbeta`) and calculate the density function (`my_dbeta`) in terms of $P$ and $\\theta$.\n  4. Generate a histogram from this distribution\nand draw a vertical line showing the mean of the distribution. Vertical lines can be drawn by using `abline(v=...)`\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-33_e856eabb634db8cc4b4e027940158cc4'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">\n1. Based just on the expressions in the normalization constant $\\Gamma(a+b)/(\\Gamma(a)\\Gamma(b))$ for the standard parameterization,\n$\\Gamma(\\theta)/(\\Gamma(\\theta P)\\Gamma(\\theta(1-P))))$ gives $\\theta=a+b$, $P=a/(a+b)$ or conversely $a = \\theta P$, $b=\\theta(1-P)$.\n\n2. In this parameterization, P is the mean proportion/ number of successes/etc. and  $\\theta$ governs the width of the distribution\n\n3.\n`my_rbeta = function(n, theta, P) {`\n\n  `rbeta(n, shape1 = theta * P, shape2 = theta * (1 - P))`\n\n`}`\n\n`my_dbeta = function(x, theta, P) {`\n\n `dbeta(x, shape1 = theta * P, shape2 = theta * (1 - P))`\n\n`}`\n\n4.\n`x = my_rbeta(1000, theta = 10, P = 0.2)`\n\n`hist(x, breaks = 50, prob = TRUE, col = \"gray\")`\n\n`curve(my_dbeta(x, theta = 10, P = 0.2), add = TRUE, lwd = 2)`\n\n`abline(v = 0.2, lwd = 2, lty = 3)`\n\n`abline(v = mean(x), lty = 2)`\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\n# Creating new distributions\n\n## Zero-inflated distributions\nThe general formula for the probability distribution of\na zero-inflated distribution, with an underlying\ndistribution $P(x)$ and a zero-inflation probability\nof $p_z$, is:\n\\begin{eqnarray*}\n\\mbox{Prob}(0) & = & p_z + (1-p_z) P(0) \\\\\n\\mbox{Prob}(x>0) & = & (1-p_z) P(x)\n\\end{eqnarray*}\nSo, for example, we could define a probability distribution\nfor a zero-inflated negative binomial as follows:\n::: {.cell hash='solution_cache/html/unnamed-chunk-34_b38068316938fabe66249775204df679'}\n\n```{.r .cell-code}\ndzinbinom = function(x,mu,size,zprob) {\n  ifelse(x==0,\n         zprob+(1-zprob)*dnbinom(0,mu=mu,size=size),\n         (1-zprob)*dnbinom(x,mu=mu,size=size))\n}\n```\n:::\n(the name, `dzinbinom`, follows the `R` convention\nfor a probability distribution function: a `d`\nfollowed by the abbreviated name of the distribution,\nin this case `zinbinom` for\n\"**z**ero-**i**nflated **n**egative\n**binom**ial\").\n\nThe `ifelse()` command checks every element of\n`x` to see whether it is zero or not and fills\nin the appropriate value depending on the answer.\n\nA random deviate generator would look like this:\n::: {.cell hash='solution_cache/html/unnamed-chunk-35_bb81d5e1361896d936e0d8b25021a780'}\n\n```{.r .cell-code}\nrzinbinom = function(n,mu,size,zprob) {\n  ifelse(runif(n)<zprob,\n         0,\n         rnbinom(n,mu=mu,size=size))\n}\n```\n:::\nThe command `runif(n)` picks `n`\nrandom values between 0 and 1; the `ifelse`\ncommand compares them with the value of\n`zprob`.  If an individual value is\nless than `zprob` (which happens with probability\n`zprob`=$p_z$), then the corresponding\nrandom number is zero; otherwise it is a value\npicked out of the appropriate negative binomial\ndistribution.\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-36_dd3a49da9dd3da059c9d32d9681d06f7'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">Check graphically that these functions actually work. For instance, you could compare the results with a negative binomial function with the same mean and variance as the data.\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-37_89c212b1e1196e1a7e91ac3f3fa993e7'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">\n`rzinbinom = function(n,mu,size,zprob) {`\n\n  `ifelse(runif(n)<zprob,`\n\n         `0,rnbinom(n,mu=mu,size=size))`\n\n`}`\n\n`a = rzinbinom(1000,mu=4,size=1,zprob=0.2)`\n\n`mean.a = mean(a)`\n\n`var.a = var(a)`\n\n`size = 1/(((var.a - mean.a))/mean.a^2)`\n\n`a1 = rnbinom(1000,mu=mean.a,size=size)`\n\n`x = as.numeric(names(table(a)))`\n\n`plot(as.numeric(table(a))~ x,type=\"h\")`\n\n`x = as.numeric(names(table(a1)))`\n\n`points(as.numeric(table(a1))~ x,type=\"p\")`\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\n# Compounding distributions\n\nThe key to compounding distributions in `R` is\nthat the functions that generate random deviates\ncan all take a vector of different parameters\nrather than a single parameter.  For example,\nif you were simulating the number of hatchlings\nsurviving (with individual probability 0.8)\nfrom a series of 8 clutches, all of size\n10, you would say\n::: {.cell hash='solution_cache/html/unnamed-chunk-38_b9d51a7492f66d51b1c03c2774e69e91'}\n\n```{.r .cell-code}\nrbinom(8,size=10,prob=0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  7  8 10  7  5  9  8  9\n```\n:::\n:::\nbut if you had a series of clutches\nof different sizes, you could still\npick all the random values at the same time:\n::: {.cell hash='solution_cache/html/unnamed-chunk-39_031962c51943804ee8f0a088af8c1c1d'}\n\n```{.r .cell-code}\nclutch_size = c(10,9,9,12,10,10,8,11)\nrbinom(8,size=clutch_size,prob=0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9 6 9 8 7 7 5 9\n```\n:::\n:::\n\nTaking this a step farther, the clutch size\nitself could be a random variable:\n::: {.cell hash='solution_cache/html/unnamed-chunk-40_e98ed5df7b2340690919e3f23a2f96b9'}\n\n```{.r .cell-code}\nclutch_size = rpois(8,lambda=10)\nrbinom(8,size=clutch_size,prob=0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  6  9  7  7  6  5 11  8\n```\n:::\n:::\nWe've just generated a Poisson-binomial\nrandom deviate ...\n\nAs a second example, I'll\nfollow Clark *et al.* in constructing\na distribution that is a compounding\nof normal distributions, with 1/variance of each sample drawn from\na gamma distribution.\n\nFirst pick the variances as the reciprocals of 10,000 values\nfrom a gamma distribution with shape 5 (setting the scale equal\nto 1/5 so the mean will be 1):\n::: {.cell hash='solution_cache/html/unnamed-chunk-41_6cd8f9d8676bda1493cf164106228b6d'}\n\n```{.r .cell-code}\nvar_vals=1/rgamma(10000,shape=5,scale=1/5)\n```\n:::\n\nTake the square root, since `dnorm` uses\nthe standard deviation and not the variance\nas a parameter:\n::: {.cell hash='solution_cache/html/unnamed-chunk-42_a58ad985b7e8db25b627d90b733140d8'}\n\n```{.r .cell-code}\nsd_vals = sqrt(var_vals)\n```\n:::\n\nGenerate 10,000 normal deviates using this\nrange of standard deviations:\n::: {.cell hash='solution_cache/html/unnamed-chunk-43_034be382f3f9df60ab8dfc30bdd4b1e2'}\n\n```{.r .cell-code}\nx = rnorm(10000,mean=0,sd=sd_vals)\n```\n:::\n\nFigure 4 shows a histogram of the\nfollowing commands:\n::: {.cell hash='solution_cache/html/unnamed-chunk-44_61edcf1cbd17afa94c1c0daebd116afd'}\n\n```{.r .cell-code}\nhist(x,prob=TRUE,breaks=100,col=\"gray\")\ncurve(dt(x,df=11),add=TRUE,lwd=2)\n```\n:::\n\n::: {.cell fig='true' hash='solution_cache/html/unnamed-chunk-45_c21ac2d87c39cfbbec9645eb0523cd4c'}\n::: {.cell-output-display}\n![Clark model: inverse gamma compounded with normal, equivalent to the Student $t$ distribution](solution_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\nThe superimposed curve is a $t$ distribution\nwith 11 degrees of freedom; it turns out that\nif the underlying gamma distribution has\nshape parameter $p$, the resulting $t$ distribution\nhas $df=2p+1$.\n(Figuring out the analytical form of the compounded\nprobability distribution or density function, or\nits equivalence to some existing distribution,\nis the hard part; for the most part, though,\nyou can find these answers in the ecological\nand statistical literature if you search hard\nenough.\n\n::: {.cell type='exercisebox' latex.options='{4}' hash='solution_cache/html/unnamed-chunk-46_6704fc3b023180e0b7cc29300c0562cb'}\n\\BeginKnitrBlock{exercisebox}\\iffalse{-123-52-125-}\\fi{}<div class=\"exercisebox\">generate 10,000 values from\na gamma-Poisson compounded distribution\nwith parameters shape=$k=0.5$, scale=$\\mu/k=4/0.5=8$\nand demonstrate that it's equivalent to a\nnegative binomial with the appropriate\n$\\mu$ and $k$ parameters.\n\n*Extra credit*: generate 10,000\nvalues from a lognormal-Poisson distribution\nwith the same expected mean and variance\n(the variance of the lognormal should\nequal the variance of the gamma distribution\nyou used as a compounding distribution;\nyou will have to do some algebra\nto figure out the values of `meanlog`\nand `sdlog` needed to produce a lognormal\nwith a specified mean and variance.\nPlot the distribution and superimpose\nthe theoretical distribution of the\nnegative binomial with the same mean\nand variance\nto see how different the shapes of the distributions\nare.\n</div>\\EndKnitrBlock{exercisebox}\n:::\n\n::: {.cell type='solutionbox' latex.options='{block-green}{4}' hash='solution_cache/html/unnamed-chunk-47_447885a0ce8fe793b9f77c0f5d11394d'}\n\\BeginKnitrBlock{solutionbox}\\iffalse{-123-98-108-111-99-107-45-103-114-101-101-110-125-123-52-125-}\\fi{}<div class=\"solutionbox\">\n`mu = 4`\n\n`k = 0.5`\n\n`x = rpois(10000, rgamma(10000, shape = k, scale = mu/k))`\n\n`plot(table(x)/10000)`\n\n`points(0:max(x), dnbinom(0:max(x), mu = mu, size = k), cex = 0.75)`\n\n</div>\\EndKnitrBlock{solutionbox}\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}