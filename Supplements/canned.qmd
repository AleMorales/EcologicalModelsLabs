---
title: "Supplement: Formula-based methods"
author: "Alejandro Morales"
date: today
visual: false
cache: true
editor: 
  markdown: 
    wrap: 72
---

# Introduction

Here I exemplify several typical statistical models with an example of
each. For each type of model I provide:

1.  Mathematical description
2.  Function implementing negative log likelihood
3.  Canned method that relies on *formula*

There are functions that allow specifying different types of models with
formulae and exist for both Maximum Likelihood and Bayesian methods. In the
case of maximum likelihood methods, they often implement methods of estimation
that are specialized to a given class of model and are therefore more efficient
than using non-linear optimization.

The formulae that are used to specify models can be slightly different for
each package, but there are some common elements that are useful to know and I
described in the section below. For possible extensions, read the documentation
of each individual package or function.

I list different possible options below, for each type of model, starting with
the simplest (linear models) up to the most general (non-linear mixed models with
non-Normal responses).

# The *formula* interface

*Work in progress*

# Overview of packages:

## `stats` 

One of the packages hat comes with R pre-installed, allows building models with
only one stochastic component. The functions in introduces are:

- `lm`: Linear models.  
- `glm`: Generalized linear models.  
- `nls`: Non-linear models. 

## `stats4`

Allows for general maximum likelihood, using both formulae and user-defined
functions for the negative log-likelihood. It introduces the `mle` function.
This allows specifying all the models in the package `stats` plus all other 
forms of non-linear and generalized non-linear models.

Note: Here we focus on the formula version of this function. If you implement
your own negative log-likelihood function you can fit any more in this document
as shown in the course.

## `bbmle`

The MLE package by Benjamin Bolker, developed in parallel with the book. This
package propposes the function `mle2` that replaces the `mle` function in `stats4` 
with similar functionality.

Note: Here we focus on the formula version of this function. If you implement
your own negative log-likelihood function you can fit any more in this document
as shown in the course.

## `nlme`

Package for linear and non-linear mixed effect models and generalized least 
squares. This is the original package developed by Pinheiro and Bates and 
associated to their mixed model book and has been one of the most popular packages
for mixed effects models in R for a long time. The functions it introduces are:

- `gls`: Linear models with generalized least squares.  
- `gnls`: Non-linear models with generalized least squares.  
- `mle`: Linear mixed effect models.  
- `nlme`: Non-linear mixed effect models.  

The package also contains many functions for modeling the variance of the
response as a function of groups and covariates (see `?varClasses`) and also
the correlation structure of residuals (see `?corClasses`).

## `lme4`

Package for linear, generalized linear and non-linear mixed effect models (the
second big package by Bates, currently maintained by Benjamin Bolker). The 
functions it introduces are:

- `lmer`: Linear mixed effect models.  
- `glmer`: Generalized linear mixed effect models.  
- `nlmer`: Non-linear mixed effect models.  

Unlike `nlme`, the package `lme4` does not allow modelling the varaince in the
response or correlation structure of residuals.

## `glmmTMB`

Package for linear,  generalized and non-linear (mixed) models. Unlike previous 
package, this
one allows random effects as optional. Developed and maintaned by Mollie Brooks,
also with contributions by Bolker. This 
package builds on top of TMB (a package for defining models in C++). It offers
a single but very versatile `glmmTMB` function that will automatically detect
the correct type of model from the formula. Like `nlme` it allows modelling the
correlation structure of the residuals, but not the variance or scale parameter.

Recently, they added the possibility of defining priors. This allows performing
Maximum a Posterior Estimation (see example in Chapter 6) but also to run the
model in Stan that implements Hamiltonian Monte Carlo for Bayesian inference. The
system for specifying priors has been take from the package `brms` (see below).


## `rstanarm`

Package for Bayesian estimation of linear and generalized (mixed) models. It is
built on top of Stan but all the C++ code is precompiled and heavily optimized,
so it is a very efficient tool for quick Bayesian modeling. The functions it 
offers are:

- `stan_lm`: Linear models.  
- `stan_glm`: Generalized linear models.  
- `stan_lmer`: Linear mixed models as in `lmer`.  
- `stan_glmer`: Generalized linear mixed models as in `glmer`.  
- `stan_nlmer`: Non-linear mixed models as in `nlmer` but only works with the
basic self-starting functions (see below for relevant section).

## `brms`

Package for Bayesian estimate that covers all the types of models described in
this document. It is built on top of Stan but unlike `rstanarm`, it will generate
ad-hoc Stan code based on the model formulated by the user. This means that the
user will have to pay the cost of compiling the model (which can often exceed
the time it takes to generate the samples) but this brings an enormous 
flexibility to the user. The only limitation (like all other packages in this
document) is that random effects must be described with Normal distribution, 
even though it is technically possible to fit models in Stan with non-Normal
random effects. The generated code may also not be the most optimal.

The package offers a single function `brm` with a very flexible formula system
(it is also useful to know the function `bf` to specify more complex formula).

# Linear responses

Models with linear are those where parameters are linear with respect to
the response variables. This does not mean that the response is linear,
it can also be a polynomial (by taking powers of covariates) but the
coefficients are always linear with respect to the response variables.
Historically the analysis of linear models has split into two
approaches:

-   Linear regression: When predictors are continuous, focuses on
    estimating parameter values.

-   Analysis of variance: When predictors are discrete, focuses on
    comparing nested models via F-test.

And there were several sub-types such as multiple linear regression,
analysis of covariance (with both discrete and continuous predictors),
etc. In the examples below I only show how to estimate parameters of
linear models.

## Linear model

Stochastic model: A single level assumed Normal.
Mean response: Linear function of covariates.
Variance response: Assumed constant.

| Paradigm    | Package   | Function  |
|-------------|-----------|-----------|
| Likelihood  | `Base`    | `lm`      |
| Likelihood  | `stats4`  | `mle`     |
| Likelihood  | `bbmle`   | `mle2`    |
| Both        | `glmmTMB` | `glmmTMB` |
| Bayesian    | `rstanarm`| `stan_lm` |
| Bayesian    | `brms`    | `brm`     |

**Example withe categorical predictor**

A linear model with a categorical predictor with 3 levels.

Data simulation:

```r
set.seed(1234)
sd  = 1
mu0 = 1
deltas = c(4, 1.5)
mus = c(mu0, mu0 + deltas)
n   = 5
groups = rep(1L:3L, each = n)
y   = rnorm(3*n, rep(mus, each = n), sd = sd)
data = data.frame(y = y, groups = groups, fgroups = as.factor(groups))
```

Explicit maximum likelihood:

```r
library(bbmle)
NLL = function(mu0, delta1, delta2, lsd, groups, y) {
  mus = c(mu0, mu0 + delta1, mu0 + delta2)[groups]
  -sum(dnorm(y, mean = mus, sd = exp(lsd), log = TRUE))
}
mle2(minuslogl = NLL, start = list(mu0 = 1, delta1 = 0, delta2 = 0, lsd = log(1)),
     data = data)

```

With `lm`:

```r
lm(y~fgroups, data = data)
```

With `mle2`:

```r
library(bbmle)
mle2(y~dnorm(mean = mu, sd = exp(lsd)), parameters = list(mu ~ fgroups),
           start = list(mu = 1, lsd = log(1)), data = data)
```

With `glmmTMB`:

```r
library(glmmTMB)
glmmTMB(y~fgroups, family = gaussian(), data = data)
```

With `rstanarm`:

```r
library(rstanarm)
stan_lm(y~fgroups, data = data, prior = NULL)
```

With `brm`

```r
library(brms)
brm(y~fgroups, data = data, family = gaussian())
```

**Example with continuous predictor**

A simple linear regression.

Data simulation:

```r
set.seed(1234)
a   = 0
b   = 1
sd  = 1
n   = 5
x   = rep(1:10, each = 5)
y   = rnorm(50, a + b*x, sd = sd)
data = data.frame(y = y, x = x)
```

Negative log-likelihood:

```r
NLL = function(mu1, mu2, mu3, sd, groups, y) {
  mus = c(mu1, mu2, mu3)[groups]
  -sum(dnorm(y, mean = mus, sd = sd, log = TRUE))
}
```

With `lm`:

```r
lm(y~fgroups, data = data)
```

With `mle2`:

```r
library(bbmle)
mle2(y~dnorm(mean = mu, sd = sd), parameters = list(mu ~ fgroups),
           start = list(mu = 3, sd = 1), data = data)
```

With `glmmTMB`:

```r
library(glmmTMB)
glmmTMB(y~fgroups, family = gaussian(), data = data)
```

With `rstanarm`:

```r
library(rstanarm)
stan_lm(y~fgroups, data = data, prior = NULL)
```

With `brm`

```r
library(brms)
brm(y~fgroups, data = data, family = gaussian())
```

## Generalized least squares

Stochastic model: A single level assumed Normal.
Mean response: Linear function of covariates.
Variance response: Non-linear function of covariates and/or correlation structure.

| Paradigm    | Package   | Function  |
|-------------|-----------|-----------|
| Likelihood  | `nlme`    | `gls`     |
| Likelihood  | `stats4`  | `mle`     |
| Likelihood  | `bbmme`   | `mle2`    |
| Bayesian    | `brms`    | `brm`     |

**Examples**

A linear model with variance increasing exponentially with covariate.

Data simulation:

```r
set.seed(1234)
a   = 0
b   = 1
c   = 0.05
n   = 5
x   = rep(1:10, each = 5)
y   = rnorm(50, a + b*x, sd = sqrt(exp(2*c*x)))
data = data.frame(y = y, x = x)
```

Negative log-likelihood:

```r
NLL = function(a, b, c, x, y) {
  mus = a + b*x
  sd  = sqrt(exp(2*c*x))
  -sum(dnorm(y, mean = mus, sd = sd, log = TRUE))
}
```

With `gls`:

``` r
summary(gls(y~x, weights = varExp(form = ~x), data = data, method = "ML"))
```
With `mle2`:

```r

```

With `brm`:

```r
brm(bf(y~x, sigma~exp(x)), data = data, family = gaussian())
```

Notes: The function `gls` allows only specific functions

## Linear mixed model

Stochastic model: Multiple levels assumed Normal.
Mean response: Linear function of covariates.
Variance response: Non-linear function of covariates and/or correlation structure.

| Paradigm    | Package   | Function    |
|-------------|-----------|-------------|
| Likelihood  | `nlme`    | `lme`       |
| Likelihood  | `lme4`    | `lmer`      | 
| Both        | `glmmTMB` | `glmmTMB`   |
| Bayesian    | `rstanarm`| `stan_lmer` |
| Bayesian    | `brms`    | `brm`       |

Note that `lmer` and `stan_lmer` allow for some correlation structure in 
residuals but do not allow modelling the variance itself. For that you need to
use `lme` or `brm`.

**Examples**
# Non-linear responses

Models where the mean is modeled by a non-linear function of covariates.

Canned only support non-linear models that can be expressed as a formula so
they must be quite simple. In Likelihood  versions, it is important to choose 
good initial values as  otherwise the algorithms will not converge. For that 
reason it is common to use self-starting functions that already specify a model 
and an internal algorithm to come up with good starting values (these are
compatible with `nls` and `gnls`.

## On self-starting functions

For non-linear models it is very important to have good initial
estimates of parameters. R has the concept of *self-starting* models. A
self-starting model implements a particular model and a procedure to
"eye-ball" the initial values:

-   Package `stats` provides `SSasymp`, `SSasympOff`, `SSasympOrig`, `SSbiexp`,
    `SSfol`, `SSfpl`, `SSgompertz`, `SSlogis`, `SSmicmen`, `SSweibull`

-   The package `nlraa` provides 28 new self-starting functions that are
    used in agricultural research but could be useful in more general
    ecological applications.

-   The package `vega` provides 4 new self-starting functions to model
    the relationship between species richness and area

See this blog post on how to write your own self-starting functions:
https://www.statforbiology.com/2020/stat_nls_selfstarting/

## Non-linear model

Stochastic model: A single level, assumed Normal.
Mean response: Non-linear function of covariates.
Variance response: Assumed constant (but see note).

| Paradigm    | Package     | Function  |
|-------------|-------------|-----------|
| Likelihood  | `Base`      | `nls`     |
| Likelihood  | `nlme`^1,2^ | `gnls`    |
| Likelihood  | `stats4`    | `mle`     |
| Likelihood  | `bbmle`^2^  | `mle2`    |
| Bayesian    | `brms`^1,2^ | `brm`     |

^1^ Correlation structure for residuals
^2^ Variance can be modeled as a non-linear function of covariates. 

**Example with constant variance**

A Michaelis-Menten model:

```r
set.seed(1234)
sd  = 1
a   = 10
b   = 3
x   = 1:10
y   = rnorm(10, mean = a*x/(b + x), sd = sd)
data = data.frame(y = y, x = x)
```

With `nls`

``` r
fit = nls(y~a*x/(b + x), start = list(a = 5, b = 2), data = data)
```

With `mle2`

``` r
fit = mle2(y~dnorm(mean = a*x/(b + x), sd = sd), start = list(a = 5, b = 2, sd = 1), data = data)
```

With `brm` 

``` r
summary(brm(y~a*x/(b + x), data = data))
```

**Example with increasing variance**

A Michaelis-Menten model with error increasing exponential with predictor

```r
fit = gnls(y~a*x/(b + x), start = list(a = 5, b = 2), 
             weights = varExp(form = ~x), data = data)
```

## Non-linear mixed models

Stochastic model: Multiple levels assumed Normal.
Mean response: Linear function of covariates after link transformation.
Variance response: Correlation structure for residuals and variance can be 
modeled as non-linear function of covariates.

| Paradigm    | Package   | Function  |
|-------------|-----------|-----------|
| Likelihood  | `nlme`    | `nlme`    |
| Bayesian    | `brms`    | `brm`     |

# Generalized linear responses

Models where the response variable is assumed different from Normal. The mean is 
modeled by a non-linear function (link) and a linear
model of covariates. In other words, these models are non-linear but the
parameters reported are linear with respect to a transformation of the mean.

Canned methods generally support a number of pre-specified distributions and link
functions. For more diversity you will have to write you own model.

## Generalized linear models

Stochastic model: A single level of one of the pre-specified distributions.
Mean response: Linear function of covariates after link transformation.
Variance response: Scale parameter (if present) assumed constant (but see note).

| Paradigm    | Package      | Function    |
|-------------|--------------|-------------|
| Likelihood  | `Base`       | `glm`       |
| Both        | `glmmTMB`^1^ | `glmmTMB`   |
| Bayesian    | `stanarm`    | `stan_glm ` |
| Bayesian    | `brms`^1,2^  | `brm`       |

^1^ Correlation structure for residuals
^2^ Scale parameter can be modeled as non-linear function of covariates.

**Example**

An Poisson model with an log link function

With `glm`

``` r
fit = glm(y~x, family = poisson(link = "log"), data = data)
```

## Generalized linear mixed models

Stochastic model: Multiple levels. The latent ones must be Normal.
Mean response: Linear function of covariates after link transformation.
Variance response: In some cases in can be modeled as a function of covariates.

| Paradigm    | Package      | Function    |
|-------------|--------------|-------------|
| Likelihood  | `lme4`       | `glmer`     |
| Both        | `glmmTMB`^1^ | `glmmTMB`   |
| Bayesian    | `stanarm`    | `stan_glmer`|
| Bayesian    | `brms`^1,2^  | `brm`       |

^1^ Correlation structure for residuals
^2^ Scale parameter can be modeled as non-linear function of covariates.


# Generalized non-linear responses

## Generalized non-linear models

Stochastic model: A single level of one of the pre-specified distributions.
Mean response: Non-linear function of covariates.
Variance response: Variance can be modeled as non-linear function of covariates.

| Paradigm    | Package   | Function  |
|-------------|-----------|-----------|
| Likelihood  | `stats4`  | `mle`     |
| Likelihood  | `bbmle`   | `mle2`    |
| Bayesian    | `brms`^1^ | `brm`     |

^1^ Also allows correlation structures

## Generalized non-linear mixed models

Stochastic model: Multiple levels. The latent ones must be Normal.
Mean response: Non-linear function of covariates.
Variance response: Correlation structure for residuals and variance can be 
modeled as non-linear function of covariates.

| Paradigm    | Package   | Function  |
|-------------|-----------|-----------|
| Bayesian    | `brms`    | `brm`     |
